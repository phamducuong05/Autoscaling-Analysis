\chapter{Xử lý dữ liệu}

\section{Tổng quan bộ dữ liệu NASA HTTP Logs}

Bộ dữ liệu được sử dụng trong dự án là \textbf{NASA WWW Server Logs}, một tập dữ liệu kinh điển trong lĩnh vực phân tích lưu lượng mạng và chuỗi thời gian. Dữ liệu này ghi lại toàn bộ các request HTTP đến máy chủ WWW của NASA trong khoảng thời gian hai tháng, từ ngày 1/7/1995 đến ngày 31/8/1995, với độ phân giải thời gian là 1 giây. Tổng số lượng request trong bộ dữ liệu là khoảng 3.46 triệu dòng log, cung cấp một bức tranh toàn diện về mẫu hình truy cập web vào giữa thập niên 1990.

Mỗi dòng log trong bộ dữ liệu NASA được lưu trữ theo định dạng ASCII chuẩn, chứa các trường thông tin quan trọng cho việc phân tích chuỗi thời gian và autoscaling. Các trường này bao gồm: \textbf{Host} là địa chỉ IP hoặc tên miền của máy khách gửi request; \textbf{Timestamp} là thời điểm request được thực hiện với định dạng \texttt{[dd/Mon/YYYY:HH:MM:SS -0400]}; \textbf{Request} là chuỗi request HTTP bao gồm phương thức (GET, POST, v.v.), đường dẫn URL và phiên bản giao thức; \textbf{Status Code} là mã phản hồi HTTP (ví dụ: 200 cho thành công, 404 cho not found, 500 cho lỗi server); và \textbf{Bytes} là số byte dữ liệu được trả về cho request.

Ví dụ một dòng log điển hình có dạng sau:
\begin{verbatim}
199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] "GET /history/apollo/ HTTP/1.0" 200 6245
\end{verbatim}
Trong ví dụ này, \texttt{199.72.81.55} là địa chỉ IP của client, \texttt{[01/Jul/1995:00:00:01 -0400]} là thời gian request với timezone UTC-4 (Eastern Time), \texttt{"GET /history/apollo/ HTTP/1.0"} là request HTTP GET đến đường dẫn \texttt{/history/apollo/}, \texttt{200} là mã trạng thái HTTP 200 (Success), và \texttt{6245} là số byte dữ liệu được trả về.

Một điểm quan trọng cần lưu ý về bộ dữ liệu này là sự tồn tại của các khoảng thời gian \textit{system downtime} do bão. Theo tài liệu chính thức của NASA, máy chủ đã gặp sự cố từ ngày 01/08/1995 14:52:01 đến ngày 03/08/1995 04:36:13 do ảnh hưởng của bão. Tuy nhiên, thay vì để lại các khoảng trống trong dữ liệu, các khoảng thời gian này đã được điền bằng dữ liệu giả lập (mock data) để duy trì tính liên tục của chuỗi thời gian. Ngoài ra, dự án cũng phát hiện thêm một khoảng thời gian có dấu hiệu bất thường từ ngày 28/07/1995 13:32:26 đến ngày 01/08/1995 00:00:00, trong đó số lượng request giảm đáng kể so với bình thường. Để đảm bảo chất lượng dữ liệu cho việc huấn luyện mô hình, các khoảng thời gian này được đánh dấu bằng cột \texttt{is\_system\_down} và các giá trị request được khôi phục bằng cách sử dụng dữ liệu từ tuần trước (shift 7 ngày).

\section{Cấu trúc dữ liệu và Pipeline xử lý}

\subsection{Log Parser và Trích xuất trường}

Pipeline xử lý dữ liệu bắt đầu bằng việc đọc và parse các file log thô từ thư mục \texttt{data/raw/}. Do dữ liệu được lưu trữ dưới dạng ASCII với cấu trúc cố định, chúng tôi sử dụng Regular Expression để trích xuất các trường thông tin một cách hiệu quả và chính xác. Biểu thức Regular Expression được sử dụng có dạng sau:
\begin{verbatim}
(?P<host>\S+) - - \[(?P<timestamp>.*?)\] "(?P<request>.*?)" (?P<status>\d{3}) (?P<bytes>\S+)
\end{verbatim}

Hàm \texttt{parse\_log\_line} chịu trách nhiệm chuyển đổi mỗi dòng log thành một dictionary với các trường đã được trích xuất. Trong quá trình này, chúng tôi thực hiện các bước xử lý sau. Đầu tiên, trích xuất \textbf{Host} bằng cách lấy địa chỉ IP hoặc tên miền của client. Tiếp theo, parse \textbf{Timestamp} và chuyển đổi chuỗi timestamp sang định dạng datetime với timezone UTC-4 để đảm bảo tính chính xác về thời gian. Sau đó, trích xuất \textbf{Request} để lấy chuỗi request HTTP đầy đủ bao gồm phương thức, đường dẫn và phiên bản giao thức. Tiếp theo, parse \textbf{Status Code} và chuyển đổi mã trạng thái sang dạng integer để dễ dàng xử lý. Cuối cùng, parse \textbf{Bytes} và chuyển đổi số byte sang dạng integer, xử lý trường hợp giá trị là \texttt{'-'} (không có dữ liệu trả về) bằng cách gán giá trị 0.

Sau khi parse tất cả các dòng log, dữ liệu được chuyển đổi thành \textbf{pandas DataFrame} và sắp xếp theo thứ tự thời gian để đảm bảo tính liên tục của chuỗi thời gian. Điều này rất quan trọng vì các mô hình chuỗi thời gian yêu cầu dữ liệu được sắp xếp theo trình tự thời gian để học được các mẫu hình phụ thuộc vào quá khứ.

\subsection{Aggregation theo thời gian}

Do dữ liệu gốc có độ phân giải là 1 giây, chúng tôi thực hiện aggregation theo các cửa sổ thời gian khác nhau để phù hợp với các mục đích phân tích và mô hình hóa. Ba cửa sổ thời gian được sử dụng trong dự án là: cửa sổ \textbf{1-minute (1m)} với 89,280 điểm dữ liệu, phù hợp cho việc phản ứng nhanh với các biến động tức thời; cửa sổ \textbf{5-minute (5m)} với 17,856 điểm dữ liệu, cân bằng tốt giữa độ nhạy và độ ổn định; và cửa sổ \textbf{15-minute (15m)} với 5,952 điểm dữ liệu, phù hợp cho các chiến lược dài hạn và giảm nhiễu.

Hàm \texttt{resample\_traffic} thực hiện aggregation với các bước sau. Đầu tiên, thiết lập cột \texttt{timestamp} làm index của DataFrame. Tiếp theo, sử dụng phương thức \texttt{resample} của pandas với các cửa sổ thời gian \texttt{'1min'}, \texttt{'5min'}, và \texttt{'15min'}. Sau đó, áp dụng các hàm aggregation cho từng trường: \texttt{requests} sử dụng \texttt{count} để đếm số lượng request trong mỗi cửa sổ; \texttt{bytes} sử dụng \texttt{sum} để tổng số byte được chuyển tải; \texttt{hosts} sử dụng \texttt{nunique} để đếm số lượng host duy nhất (đại diện cho số lượng người dùng); và \texttt{errors} sử dụng \texttt{lambda x: (x >= 400).sum()} để đếm số lượng lỗi (status code $\ge$ 400). Cuối cùng, \textbf{Fill missing values} bằng cách điền 0 cho các khoảng thời gian không có request để đảm bảo tính liên tục của chuỗi thời gian.

\subsection{Xử lý missing values và anomalies}

Sau khi aggregation, chúng tôi thực hiện các bước xử lý để đảm bảo chất lượng dữ liệu. Đầu tiên, xử lý \textbf{System Downtime} bằng cách tạo cột \texttt{is\_system\_down} để đánh dấu các khoảng thời gian có dữ liệu giả lập. Các giá trị request trong khoảng này được khôi phục bằng cách sử dụng dữ liệu từ tuần trước (shift 2016 bước cho 5-minute window, tương ứng với 7 ngày). Sau đó, thực hiện \textbf{Forward-fill và Backward-fill} bằng cách sử dụng phương thức forward-fill (sử dụng giá trị trước đó) và backward-fill (sử dụng giá trị sau đó) để đảm bảo tính liên tục của chuỗi thời gian. Tiếp theo, loại bỏ các giá trị infinity có thể xuất hiện sau khi tính toán các đặc trưng thống kê. Cuối cùng, thực hiện \textbf{Type casting} bằng cách chuyển đổi các cột sang kiểu dữ liệu phù hợp (int cho requests, bytes, hosts; float cho các đặc trưng thống kê) để tối ưu hóa bộ nhớ và tốc độ xử lý.

\section{Phân tích khám phá dữ liệu (EDA)}

\subsection{Thống kê tổng quan}

Sau khi xử lý và làm sạch dữ liệu, chúng tôi thực hiện phân tích khám phá dữ liệu (Exploratory Data Analysis - EDA) để hiểu rõ các đặc điểm và mẫu hình của lưu lượng truy cập NASA. Thống kê cơ bản cho khung 5-minute cho thấy tổng số điểm dữ liệu là 17,856, khoảng thời gian từ 01/07/1995 00:00:00 đến 31/08/1995 23:55:00 (UTC-4). Trung bình số request mỗi 5 phút là khoảng 200-300 request. Peak traffic đạt mức cao nhất vào các giờ làm việc trong ngày (9h-17h) phản ánh hành vi người dùng điển hình vào giờ làm việc. Low traffic giảm đáng kể vào các giờ đêm (0h-6h) và cuối tuần, phản ánh sự khác biệt trong hành vi truy cập giữa ngày làm việc và thời gian nghỉ ngơi.

\subsection{Phân phối Status Codes}

Phân tích mã trạng thái HTTP cho thấy các đặc điểm sau. Mã \textbf{200 (Success)} chiếm phần lớn các request, cho thấy hệ thống hoạt động ổn định và trả về dữ liệu thành công cho hầu hết các request. Mã \textbf{304 (Not Modified)} xuất hiện thường xuyên do client sử dụng cache để giảm tải cho server. Mã \textbf{404 (Not Found)} có tỷ lệ thấp, cho thấy cấu trúc website được duy trì tốt và các đường dẫn không bị hỏng nhiều. Mã \textbf{500 (Server Error)} rất hiếm, cho thấy hệ thống có độ tin cậy cao và ít gặp sự cố nghiêm trọng.

Tỷ lệ lỗi được tính toán bằng công thức sau để đánh giá chất lượng hệ thống:
\begin{equation}
\text{error\_rate} = \frac{\text{errors}}{\text{requests}}
\end{equation}
Trong đó \texttt{errors} là số lượng request có status code $\ge$ 400. Tỷ lệ lỗi trung bình trong toàn bộ bộ dữ liệu rất thấp, thường dưới 1\%, cho thấy hệ thống hoạt động ổn định và đáng tin cậy.

\subsection{Mẫu hình Traffic theo thời gian}

Biểu đồ traffic theo thời gian (Hình \ref{fig:traffic_overview}) cho thấy các mẫu hình rõ ràng về chu kỳ hàng ngày và hàng tuần. Chu kỳ \textbf{hàng ngày} thể hiện rõ nét với traffic tăng mạnh vào các giờ làm việc (9h-17h) và giảm vào ban đêm (0h-6h), phản ánh hành vi người dùng điển hình trong ngày làm việc. Chu kỳ \textbf{hàng tuần} cho thấy traffic cao hơn vào các ngày trong tuần (Thứ 2 - Thứ 6) và thấp hơn vào cuối tuần (Thứ 7 - Chủ Nhật), phản ánh sự khác biệt trong hành vi truy cập giữa ngày làm việc và cuối tuần. Các \textbf{sự kiện bất thường} được đánh dấu bằng vùng màu đỏ thể hiện các khoảng thời gian system downtime do bão, trong đó traffic giảm đáng kể do dữ liệu giả lập.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{images/chapter2_traffic_overview.png}
    \caption{Tổng quan Traffic 2 tháng và Sự kiện Bão}
    \label{fig:traffic_overview}
\end{figure}

\subsection{Phân tích theo Giờ và Thứ}

Biểu đồ phân bố traffic theo giờ trong ngày (Hình \ref{fig:seasonality}) cho thấy các đặc điểm sau. \textbf{Giờ cao điểm} từ 10h-16h có lượng request cao nhất, phản ánh thời gian làm việc chính thức. \textbf{Giờ thấp điểm} từ 0h-6h có lượng request thấp nhất, phản ánh thời gian nghỉ ngơi của người dùng. Độ biến động của traffic ở các giờ cao điểm lớn hơn, phản ánh sự không ổn định của traffic trong giờ làm việc.

Biểu đồ phân bố traffic theo thứ trong tuần cho thấy các đặc điểm sau. \textbf{Ngày trong tuần} như Thứ 3, Thứ 4, Thứ 5 có traffic cao nhất, có thể do đây là những ngày làm việc bận rộn nhất trong tuần. \textbf{Cuối tuần} như Thứ 7 và Chủ Nhật có traffic thấp hơn đáng kể, phản ánh hành vi người dùng ít truy cập vào ngày nghỉ ngơi.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{images/chapter2_seasonality_analysis.png}
    \caption{Phân bố Traffic theo Giờ và Thứ trong tuần}
    \label{fig:seasonality}
\end{figure}

\subsection{So sánh 3 khung thời gian}

Biểu đồ so sánh traffic giữa 3 khung thời gian (Hình \ref{fig:window_comparison}) cho thấy các đặc điểm khác nhau của mỗi cửa sổ. \textbf{Khung 1m} cho thấy chi tiết cao nhất nhưng có nhiều nhiễu, phù hợp cho việc phản ứng nhanh với các biến động tức thời nhưng khó dự báo do nhiễu lớn. \textbf{Khung 5m} cân bằng tốt giữa chi tiết và độ ổn định, giảm nhiễu đáng kể so với khung 1m nhưng vẫn giữ được các mẫu hình quan trọng. \textbf{Khung 15m} mượt mà hơn nhưng mất đi một số chi tiết quan trọng, phù hợp cho các chiến lược dài hạn và giảm nhiễu tối đa.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{images/chapter2_window_comparison.png}
    \caption{So sánh Traffic giữa 3 khung thời gian}
    \label{fig:window_comparison}
\end{figure}

\section{Feature Engineering}

\subsection{Time-based Features}

Để nắm bắt các mẫu hình theo thời gian, chúng tôi tạo ra các đặc trưng dựa trên thời gian. \textbf{hour\_of\_day} là giờ trong ngày (0-23) phản ánh chu kỳ hàng ngày của traffic. \textbf{day\_of\_week} là thứ trong tuần (0-6, với 0 là Thứ 2) phản ánh chu kỳ hàng tuần của traffic. \textbf{is\_weekend} là biến nhị phân (0/1) chỉ ra ngày cuối tuần, giúp phân biệt hành vi người dùng giữa ngày làm việc và cuối tuần.

\subsection{Cyclical Encoding}

Để mô hình hiểu được tính chu kỳ của thời gian (ví dụ: 23h và 0h gần nhau hơn 23h và 12h), chúng tôi sử dụng \textit{Cyclical Encoding} với các hàm sin và cos. Cách tiếp cận này giúp mô hình học được các mẫu hình chu kỳ mà không bị nhầm lẫn bởi sự gián đoạn tại các điểm biên. Các công thức được sử dụng như sau:

\begin{equation}
\text{hour\_sin} = \sin\left(\frac{2\pi \times \text{hour\_of\_day}}{24}\right)
\end{equation}
\begin{equation}
\text{hour\_cos} = \cos\left(\frac{2\pi \times \text{hour\_of\_day}}{24}\right)
\end{equation}

\subsection{Lag Features}

Để nắm bắt tính autoregressive của chuỗi thời gian, chúng tôi tạo ra các đặc trưng lag. \textbf{req\_lag\_1} là giá trị request tại thời điểm $t-1$, giúp capture các mẫu hình ngắn hạn và phản ứng nhanh với các biến động tức thời. \textbf{req\_lag\_12} là giá trị request tại thời điểm $t-12$ (1 giờ trước cho khung 5m), giúp capture chu kỳ hàng ngày của traffic. \textbf{req\_lag\_288} là giá trị request tại thời điểm $t-288$ (24 giờ trước cho khung 5m), giúp capture chu kỳ hàng tuần của traffic. Các đặc trưng lag này đặc biệt quan trọng cho các mô hình như ARIMA và LSTM, giúp mô hình học được các mẫu hình phụ thuộc vào quá khứ.

\subsection{Rolling Statistics}

Để nắm bắt xu hướng và độ biến động của traffic, chúng tôi tính toán các thống kê rolling. \textbf{rolling\_mean\_1h} là trung bình động trong 1 giờ (12 bước cho khung 5m), phản ánh xu hướng ngắn hạn của traffic. \textbf{rolling\_std\_1h} là độ lệch chuẩn động trong 1 giờ, phản ánh độ biến động ngắn hạn của traffic. \textbf{rolling\_mean\_24h} là trung bình động trong 24 giờ (288 bước cho khung 5m), phản ánh xu hướng dài hạn của traffic. Các đặc trưng này giúp mô hình nhận diện các giai đoạn tăng trưởng, giảm sút và ổn định của traffic.

\section{Aggregation và Train/Test Split}

\subsection{Train/Test Split theo trình tự thời gian}

Đối với bài toán chuỗi thời gian, việc split dữ liệu phải tuân thủ nguyên tắc \textit{chronological split} - không được random shuffle vì sẽ làm mất tính liên tục của thời gian. Chúng tôi thực hiện split như sau: \textbf{Training set} từ 01/07/1995 đến 22/08/1995 (khoảng 52 ngày), chiếm khoảng 85\% dữ liệu. \textbf{Test set} từ 23/08/1995 đến 31/08/1995 (khoảng 9 ngày), chiếm khoảng 15\% dữ liệu. Tỷ lệ train/test là khoảng 85\%/15\%, phù hợp cho việc đánh giá khả năng dự báo của mô hình.

Việc split theo trình tự thời gian có những ưu điểm quan trọng. Đầu tiên, \textbf{Giả lập thực tế}: Mô hình được huấn luyện trên quá khứ và dự báo cho tương lai, giả lập đúng cách mà các hệ thống dự báo hoạt động trong thực tế. Thứ hai, \textbf{Tránh data leakage}: Không có thông tin từ tương lai "rò rỉ" vào tập training, đảm bảo tính công bằng của đánh giá mô hình. Tuy nhiên, việc split theo trình tự thời gian cũng có nhược điểm. Nếu mẫu hình traffic thay đổi đáng kể giữa train và test (concept drift), mô hình có thể hoạt động kém. Ngoài ra, nếu test set chứa các sự kiện đặc biệt không có trong train set, dự báo sẽ kém chính xác.

\subsection{Lưu trữ dữ liệu}

Sau khi xử lý hoàn tất, 3 bộ dữ liệu được lưu trữ trong thư mục \texttt{data/cleaned/} để sử dụng cho việc huấn luyện và đánh giá các mô hình. \texttt{data\_1m.csv} là dữ liệu aggregation theo 1 phút với 89,280 điểm dữ liệu. \texttt{data\_5m.csv} là dữ liệu aggregation theo 5 phút với 17,856 điểm dữ liệu. \texttt{data\_15m.csv} là dữ liệu aggregation theo 15 phút với 5,952 điểm dữ liệu. Các file này được sử dụng trực tiếp cho việc huấn luyện và đánh giá các mô hình trong các chương tiếp theo.
