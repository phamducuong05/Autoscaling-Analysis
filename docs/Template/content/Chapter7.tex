\chapter{\texorpdfstring{Autoscaling \& Demo}{Autoscaling and Demo}}

\section{Thuật toán Autoscaling}

\subsection{Chiến lược AI Predictive Scaling (Gen 2)}

Đây là chiến lược nòng cốt của đồ án, được thiết kế để khắc phục hoàn toàn nhược điểm "độ trễ" (Lag) của các phương pháp truyền thống. Thuật toán không chỉ dựa vào dự báo đơn thuần mà còn tích hợp một "hệ thống ra quyết định lai ghép" (Hybrid Decision Engine) nhằm đảm bảo tính an toàn tuyệt đối cho hệ thống. Quy trình xử lý gồm 4 tầng bảo vệ:

\subsubsection{Tầng 1: Phát hiện Bất thường (Anomaly Detection)}
Trước khi thực hiện dự báo, hệ thống kiểm tra tín hiệu đầu vào để loại bỏ các trượng hợp tấn công từ chối dịch vụ (DDoS) hoặc lỗi dữ liệu.
\begin{equation}
    is\_ddos = (Forecast > 10) \land (CurrentLoad > Forecast \times Multiplier_{ddos})
\end{equation}
Nếu phát hiện bất thường (DDoS), hệ thống sẽ chuyển sang chế độ "Safety Mode", bỏ qua dự báo và cấp phát tài nguyên dựa trên tải thực tế nhưng bị giới hạn bởi ngưỡng trần (\texttt{ddos\_max\_servers}) để tránh bùng nổ chi phí.

\subsubsection{Tầng 2: Hệ số An toàn Thích ứng (Adaptive Safety Margin)}
Thay vì nhân một hệ số an toàn cố định (Fixed Multiplier), hệ thống sử dụng thuật toán \textbf{$K$-Sigma} để tính toán vùng đệm an toàn dựa trên độ tin cậy của mô hình tại thời điểm đó. Hệ số $K$ biến thiên theo hệ số biến thiên ($CV = \sigma / \mu$):

\begin{equation}
    K = \begin{cases} 
      1.0 & CV < 0.1 \quad \text{(Tin cậy cao - Tiết kiệm tối đa)} \\
      1.2 & 0.1 \le CV \le 0.3 \quad \text{(Bình thường)} \\
      1.35 & CV > 0.3 \quad \text{(Biến động mạnh - Tăng đệm an toàn)}
   \end{cases}
\end{equation}

Từ đó, nhu cầu dự báo (\texttt{Demand}) được tính toán:
\begin{equation}
    Demand_{predict} = \lceil \frac{Forecast + (K \times \sigma)}{Capacity_{server}} \rceil
\end{equation}
Công thức này cho phép hệ thống tự động "nới lỏng" hoặc "thắt chặt" tài nguyên một cách thông minh, tối ưu hóa chi phí khi tải ổn định và tăng độ an toàn khi tải biến động.

\subsubsection{Tầng 3: Mạng lưới an toàn Reactive (Reactive Safety Net)}
Để đề phòng trường hợp mô hình dự báo sai (Under-prediction), hệ thống luôn tính toán song song một giá trị nhu cầu dựa trên tải thực tế hiện tại (\texttt{Demand\_React}). Quyết định cuối cùng là giá trị lớn nhất của cả hai:
\begin{equation}
    Demand_{final} = \max(Demand_{predict}, Demand_{react})
\end{equation}
Cơ chế này đảm bảo hệ thống không bao giờ cấp phát ít tài nguyên hơn nhu cầu thực tế, giữ vững cam kết SLA.

\subsubsection{Tầng 4: Ổn định theo Đỉnh (Peak-Driven Stability)}
Để tránh hiện tượng dao động (Flapping), hệ thống không sử dụng giá trị tức thời mà sử dụng cửa sổ ổn định (Stability Window) 5 phút. Điểm đặc biệt là chúng tôi sử dụng toán tử \textbf{MAX} (thay vì Average):
\begin{equation}
    ScaleTarget = \max(History_{t-5} \dots History_{t})
\end{equation}
Cách tiếp cận này gọi là \textit{"Peak-Driven Scaling"}: Hệ thống sẽ phản ứng theo đỉnh tải cao nhất dự báo được trong tương lai gần. Điều này cho phép bắt trọn các đợt tăng tải đột biến (Spikes) dù chúng chỉ kéo dài 1-2 phút, giải quyết triệt để bài toán rớt gói tin ở các hệ thống nhạy cảm.

Bảng \ref{tab:scaling_strategies} tóm tắt cấu hình tham số thực tế của các chiến lược:

\begin{table}[H]
    \centering
    \caption{Cấu hình Chiến lược Scaling}
    \label{tab:scaling_strategies}
    \begin{tabular}{lccc}
        \toprule
        Chiến lược & Logic Scale-Out & Logic Scale-In & Cooldown (Out/In) \\
        \midrule
        Static & N/A & N/A & N/A \\
        Reactive & Load > 80\% & Load < 40\% & 10m / 10m \\
        \textbf{AI (Gen 2)} & $\max(Forecast) + K\sigma$ & Adaptive Factor & \textbf{2m / 4m} \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{\texorpdfstring{Config \& Tham số tối ưu}{Config and Tham số tối ưu}}

Để đạt được hiệu năng tối ưu (Global Optima), hệ thống được tinh chỉnh với các tham số "Lean \& Fast" như sau:

\begin{itemize}
    \item \textbf{Stability Window}: Sử dụng hàm \textbf{MAX} trong cửa sổ 5 phút. Việc dùng hàm Max thay vì Average giúp hệ thống bắt trọn mọi tín hiệu tăng đột biến (Spike) dù chỉ kéo dài 1-2 phút.
    \item \textbf{Dynamic Safety Factor (K)}:
    \begin{equation}
        K = \begin{cases} 
              1.0 & CV < 0.1 \quad \text{(Tin cậy cao - Tiết kiệm tối đa)} \\
              1.2 & 0.1 \le CV \le 0.3 \\
              1.35 & CV > 0.3 \quad \text{(Biến động mạnh - Tăng bộ đệm an toàn)}
           \end{cases}
    \end{equation}
    \item \textbf{Cost Model}: Server Rate = \$0.05/giờ, SLA Penalty = \$0.02/request rớt.
\end{itemize}

\section{\texorpdfstring{Kết quả Thực nghiệm \& Phân tích}{Kết quả Thực nghiệm và Phân tích}}

Chúng tôi tiến hành Benchmark trên tập dữ liệu NASA-HTTP (resampled 5 phút) mô phỏng lại tải thực tế trong 3.5 ngày. Kết quả được ghi nhận như sau.

\subsection{Biểu đồ thích ứng tải}

Hình \ref{fig:benchmark_plot} minh hoạt khả năng bám sát tải của các chiến lược.

\begin{figure}[H]
    \centering
    % Placeholder cho ảnh evaluation_results/benchmark_plot.png
    \includegraphics[width=1.0\textwidth]{images/chapter7_scaling_behavior.jpg}
    \caption{So sánh hành vi scaling: AI (Xanh lá) bám sát tải thực tế, trong khi Static (Đỏ chấm) lãng phí tài nguyên và Reactive (Cam) có độ trễ.}
    \label{fig:benchmark_plot}
\end{figure}

Từ biểu đồ, ta có thể quan sát thấy:
\begin{enumerate}
    \item \textbf{Đường màu xanh lá (AI)}: Có độ nhạy cực cao. Ngay trước khi tải thật (màu xám) tăng vọt, AI đã dự báo và tăng server đón đầu. Đặc biệt ở các đoạn "răng cưa", AI cắt giảm server sâu hơn Reactive, giúp tiết kiệm chi phí.
    \item \textbf{Đường màu cam (Reactive)}: Luôn đi sau tải một nhịp (Lag phase), dẫn đến việc thiếu tài nguyên ở sườn lên (gây rớt gói) và dư thừa tài nguyên ở sườn xuống.
\end{enumerate}

\subsection{Phân tích định lượng}

Bảng số liệu chi tiết (được trích xuất từ báo cáo benchmark tự động) khẳng định sự vượt trội của AI.

\begin{table}[H]
    \centering
    \caption{Báo cáo Hiệu năng Tổng hợp}
    \label{tab:benchmark_metrics}
    % Placeholder cho nội dung bảng từ report.md
    \begin{tabular}{lcccccc}
        \toprule
        Chiến lược & Total Requests & Dropped & Drop Rate & Cost (\$) & Avg Servers & Efficiency \\
        \midrule
        AI Gen 2 & 219,294 & \textbf{37} & \textbf{0.02\%} & \textbf{\$68.32} & \textbf{16.4} & \textbf{\$0.3115} \\
        Reactive & 219,294 & 105 & 0.05\% & \$80.99 & 19.2 & \$0.3693 \\
        Static (Max) & 219,294 & 0 & 0.00\% & \$144.08 & 35.0 & \$0.6570 \\
        \bottomrule
    \end{tabular}
\end{table}

\textbf{Kết luận quan trọng:}

\begin{enumerate}
    \item \textbf{Về chi phí (Cost Efficiency)}:
    \begin{itemize}
        \item AI là chiến lược tiết kiệm nhất (\$68.32). So với Static (\$144.08), AI giúp tiết kiệm \textbf{52.5\%} chi phí vận hành.
        \item So với Reactive (\$80.99), AI vẫn rẻ hơn \textbf{15.6\%} nhờ khả năng scale-in (thu hồi tài nguyên) thông minh hơn ở các khung giờ thấp điểm.
    \end{itemize}
    
    \item \textbf{Về độ ổn định (SLA Compliance)}:
    \begin{itemize}
        \item AI đạt tỷ lệ rớt gói tin (Drop Rate) chỉ \textbf{0.02\%} (37 requests trên tổng số 219k). Con số này tốt hơn 2.5 lần so với Reactive (0.05\%).
        \item Điều này chứng minh rằng việc sử dụng cơ chế \textit{Peak-Driven} (dùng hàm MAX) đã khắc phục hoàn toàn điểm yếu về độ trễ của các thuật toán dự báo thông thường.
    \end{itemize}
\end{enumerate}

Tóm lại, giải pháp AI Predictive Scaling đề xuất đã đạt được mục tiêu kép: \textbf{Rẻ nhất} và \textbf{An toàn nhất} (trong nhóm Dynamic Scaling), chứng minh tính khả thi để áp dụng vào môi trường thực tế.


\section{Demo Hệ thống}

Để minh họa khả năng hoạt động thực tế của thuật toán AI Predictive Scaling (Gen 2), chúng tôi đã xây dựng một hệ thống Demo hoàn chỉnh theo kiến trúc Client-Server. Hệ thống cho phép mô phỏng lại lưu lượng truy cập lịch sử (Replay Traffic) và quan sát phản ứng của AI trong thời gian thực.

\subsection{Kiến trúc hệ thống}

Hệ thống Demo được chia thành hai phân hệ độc lập, giao tiếp với nhau qua chuẩn RESTful API:

\begin{enumerate}
    \item \textbf{Backend Service (API Layer)}: Được xây dựng bằng \textbf{FastAPI} (Python), đóng vai trò là "bộ não" xử lý trung tâm. Service này chứa hai components chính:
    \begin{itemize}
        \item \textit{Inference Engine}: Chịu trách nhiệm load model LSTM đã huấn luyện và thực hiện dự báo (Forecast).
        \item \textit{Autoscaler Core}: Chứa toàn bộ logic stateful của thuật toán Gen 2 (Stability Window, Cooldown, Adaptive Safety Factor).
    \end{itemize}
    
    \item \textbf{Frontend Dashboard (Visualization Layer)}: Sử dụng \textbf{Streamlit}, đóng vai trò là giao diện điều khiển và giám sát. Dashboard thực hiện vòng lặp mô phỏng (Simulation Loop), gửi data từng phút lên Backend và hiển thị kết quả phản hồi dưới dạng biểu đồ thời gian thực.
\end{enumerate}

\subsection{API Specification}

Backend cung cấp hai endpoints chính để phục vụ quá trình scaling:

\subsubsection{1. Forecast Endpoint (@[api])}
\texttt{POST /forecast}

Endpoint này nhận vào dữ liệu lịch sử tải (các bước thời gian trước đó) và trả về giá trị dự báo cho bước tiếp theo, kèm theo độ lệch chuẩn ($\sigma$) để tính toán độ tin cậy.

\begin{itemize}
    \item \textbf{Input}: \texttt{recent\_history} (List[float]), \texttt{error\_history} (List[float]), \texttt{hour\_sin/cos} (Feature Engineering).
    \item \textbf{Output}: 
    \begin{itemize}
        \item \texttt{forecast\_load}: Giá trị dự báo tải trung bình.
        \item \texttt{sigma}: Độ lệch chuẩn dùng để tính khoảng tin cậy (Confidence Interval).
        \item \texttt{cv}: Hệ số biến thiên (Coefficient of Variation) dùng để quyết định hệ số an toàn $K$.
    \end{itemize}
\end{itemize}

\subsubsection{2. Scaling Decision Endpoint}
\texttt{POST /recommend-scaling}

Endpoint này là nơi chứa "bộ não" của hệ thống autoscaling. Nó nhận vào tải hiện tại và tải dự báo, sau đó chạy qua chuỗi logic quyết định (Anomaly Detection $\rightarrow$ Safety Factor $\rightarrow$ Stability Window $\rightarrow$ Cooldown).

\begin{itemize}
    \item \textbf{Output}: 
    \begin{itemize}
        \item \texttt{servers}: Số lượng server mục tiêu.
        \item \texttt{action}: Hành động cụ thể (SCALE\_OUT, SCALE\_IN, HOLD, WAIT\_COOLDOWN).
        \item \texttt{details}: Metadata chi tiết để debug (Cost, Dropped requests, v.v.).
    \end{itemize}
\end{itemize}

\subsection{Dashboard Giám sát}

Giao diện Dashboard được thiết kế để cung cấp cái nhìn toàn cảnh về hoạt động của hệ thống.

\begin{enumerate}
    \item \textbf{Real-time Chart}: Biểu đồ Plotly cập nhật trực tiếp theo từng bước mô phỏng (Step), hiển thị 3 đường tín hiệu quan trọng:
    \begin{itemize}
        \item \textit{Actual Load (Màu xanh dương)}: Tải thực tế từ dataset.
        \item \textit{AI Forecast (Màu cam)}: Đường dự báo kèm theo vùng bóng mờ (Shaded Area) thể hiện khoảng tin cậy $2\sigma$.
        \item \textit{System Capacity (Nét đứt màu xanh lá)}: Tổng năng lực phục vụ của hệ thống. Khi đường này nằm trên đường Load nghĩa là hệ thống an toàn.
    \end{itemize}
    
    \item \textbf{Metrics Panel}: Hiển thị các chỉ số KPI quan trọng:
    \begin{itemize}
        \item \textbf{Total Cost}: Chi phí hạ tầng tích lũy + Phạt SLA.
        \item \textbf{AI Confidence (CV)}: Độ tự tin của model. Màu sắc của metric này sẽ đảo chiều (Inverse) để cảnh báo khi độ tin cậy thấp (CV cao).
        \item \textbf{System Status}: Trạng thái hiện tại (Stable, Scaling, hay Warming Up).
    \end{itemize}
    
    \item \textbf{Simulation Controls}: Thanh trượt bên trái cho phép người dùng điều chỉnh tốc độ mô phỏng (Speed ms) và chọn khoảng thời gian (Minute Index) để test các tình huống cụ thể (ví dụ: test khả năng chịu tải lúc 2h sáng).
\end{enumerate}