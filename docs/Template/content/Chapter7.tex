\chapter{\texorpdfstring{Autoscaling \& Demo}{Autoscaling and Demo}}

\section{Thuật toán Autoscaling}

\subsection{Chiến lược scaling}

Để giải quyết bài toán cân bằng giữa chi phí hạ tầng và cam kết chất lượng dịch vụ (SLA), đồ án đã triển khai và so sánh ba chiến lược scaling khác nhau. Sự khác biệt cốt lõi nằm ở độ chủ động (Proactive) và khả năng thích ứng (Adaptive) của thuật toán.

\begin{enumerate}
    \item \textbf{Static Scaling (Fixed Capacity)}: Cấp phát tài nguyên cố định ở mức tối đa (Max Servers = 35) để đảm bảo không bao giờ thiếu hụt tài nguyên. Đây là chiến lược "an toàn nhưng lãng phí", đóng vai trò là Baseline (đường cơ sở) để so sánh độ hiệu quả.
    
    \item \textbf{Reactive Scaling (Threshold-based)}: Chiến lược phản ứng truyền thống dựa trên ngưỡng sử dụng CPU/Request. Hệ thống sẽ tăng server khi tải vượt quá 80\% capacity và giảm khi dưới 40\%. Nhược điểm cố hữu là độ trễ (Lag) do phải chờ tải thực sự tăng mới bắt đầu phản ứng.
    
    \item \textbf{AI Predictive Scaling (Gen 2)}: Chiến lược đề xuất của đồ án. Hệ thống sử dụng mô hình LSTM để dự báo tải trong 15 phút tới. Điểm đột phá nằm ở cơ chế \textit{"Peak-Driven Scaling"}: thay vì scale theo giá trị trung bình, hệ thống luôn scale theo \textbf{đỉnh tải dự báo cao nhất} trong khung thời gian tới, cộng thêm một lớp đệm an toàn động ($K \times \sigma$). Điều này giúp loại bỏ hoàn toàn độ trễ.
\end{enumerate}

Bảng \ref{tab:scaling_strategies} tóm tắt cấu hình tham số thực tế của các chiến lược:

\begin{table}[H]
    \centering
    \caption{Cấu hình Chiến lược Scaling}
    \label{tab:scaling_strategies}
    \begin{tabular}{lccc}
        \toprule
        Chiến lược & Logic Scale-Out & Logic Scale-In & Cooldown (Out/In) \\
        \midrule
        Static & N/A & N/A & N/A \\
        Reactive & Load > 80\% & Load < 40\% & 10m / 10m \\
        \textbf{AI (Gen 2)} & $\max(Forecast) + K\sigma$ & Adaptive Factor & \textbf{2m / 4m} \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{\texorpdfstring{Config \& Tham số tối ưu}{Config and Tham số tối ưu}}

Để đạt được hiệu năng tối ưu (Global Optima), hệ thống được tinh chỉnh với các tham số "Lean \& Fast" như sau:

\begin{itemize}
    \item \textbf{Stability Window}: Sử dụng hàm \textbf{MAX} trong cửa sổ 5 phút. Việc dùng hàm Max thay vì Average giúp hệ thống bắt trọn mọi tín hiệu tăng đột biến (Spike) dù chỉ kéo dài 1-2 phút.
    \item \textbf{Dynamic Safety Factor (K)}:
    \begin{equation}
        K = \begin{cases} 
              1.0 & CV < 0.1 \quad \text{(Tin cậy cao - Tiết kiệm tối đa)} \\
              1.2 & 0.1 \le CV \le 0.3 \\
              1.35 & CV > 0.3 \quad \text{(Biến động mạnh - Tăng bộ đệm an toàn)}
           \end{cases}
    \end{equation}
    \item \textbf{Cost Model}: Server Rate = \$0.05/giờ, SLA Penalty = \$0.02/request rớt.
\end{itemize}

\section{\texorpdfstring{Kết quả Thực nghiệm \& Phân tích}{Kết quả Thực nghiệm và Phân tích}}

Chúng tôi tiến hành Benchmark trên tập dữ liệu NASA-HTTP (resampled 5 phút) mô phỏng lại tải thực tế trong 3.5 ngày. Kết quả được ghi nhận như sau.

\subsection{Biểu đồ thích ứng tải}

Hình \ref{fig:benchmark_plot} minh hoạt khả năng bám sát tải của các chiến lược.

\begin{figure}[H]
    \centering
    % Placeholder cho ảnh evaluation_results/benchmark_plot.png
    \includegraphics[width=1.0\textwidth]{images/chapter7_scaling_behavior.jpg}
    \caption{So sánh hành vi scaling: AI (Xanh lá) bám sát tải thực tế, trong khi Static (Đỏ chấm) lãng phí tài nguyên và Reactive (Cam) có độ trễ.}
    \label{fig:benchmark_plot}
\end{figure}

Từ biểu đồ, ta có thể quan sát thấy:
\begin{enumerate}
    \item \textbf{Đường màu xanh lá (AI)}: Có độ nhạy cực cao. Ngay trước khi tải thật (màu xám) tăng vọt, AI đã dự báo và tăng server đón đầu. Đặc biệt ở các đoạn "răng cưa", AI cắt giảm server sâu hơn Reactive, giúp tiết kiệm chi phí.
    \item \textbf{Đường màu cam (Reactive)}: Luôn đi sau tải một nhịp (Lag phase), dẫn đến việc thiếu tài nguyên ở sườn lên (gây rớt gói) và dư thừa tài nguyên ở sườn xuống.
\end{enumerate}

\subsection{Phân tích định lượng}

Bảng số liệu chi tiết (được trích xuất từ báo cáo benchmark tự động) khẳng định sự vượt trội của AI.

\begin{table}[H]
    \centering
    \caption{Báo cáo Hiệu năng Tổng hợp}
    \label{tab:benchmark_metrics}
    % Placeholder cho nội dung bảng từ report.md
    \begin{tabular}{lcccccc}
        \toprule
        Chiến lược & Total Requests & Dropped & Drop Rate & Cost (\$) & Avg Servers & Efficiency \\
        \midrule
        AI Gen 2 & 219,294 & \textbf{37} & \textbf{0.02\%} & \textbf{\$68.32} & \textbf{16.4} & \textbf{\$0.3115} \\
        Reactive & 219,294 & 105 & 0.05\% & \$80.99 & 19.2 & \$0.3693 \\
        Static (Max) & 219,294 & 0 & 0.00\% & \$144.08 & 35.0 & \$0.6570 \\
        \bottomrule
    \end{tabular}
\end{table}

\textbf{Kết luận quan trọng:}

\begin{enumerate}
    \item \textbf{Về chi phí (Cost Efficiency)}:
    \begin{itemize}
        \item AI là chiến lược tiết kiệm nhất (\$68.32). So với Static (\$144.08), AI giúp tiết kiệm \textbf{52.5\%} chi phí vận hành.
        \item So với Reactive (\$80.99), AI vẫn rẻ hơn \textbf{15.6\%} nhờ khả năng scale-in (thu hồi tài nguyên) thông minh hơn ở các khung giờ thấp điểm.
    \end{itemize}
    
    \item \textbf{Về độ ổn định (SLA Compliance)}:
    \begin{itemize}
        \item AI đạt tỷ lệ rớt gói tin (Drop Rate) chỉ \textbf{0.02\%} (37 requests trên tổng số 219k). Con số này tốt hơn 2.5 lần so với Reactive (0.05\%).
        \item Điều này chứng minh rằng việc sử dụng cơ chế \textit{Peak-Driven} (dùng hàm MAX) đã khắc phục hoàn toàn điểm yếu về độ trễ của các thuật toán dự báo thông thường.
    \end{itemize}
\end{enumerate}

Tóm lại, giải pháp AI Predictive Scaling đề xuất đã đạt được mục tiêu kép: \textbf{Rẻ nhất} và \textbf{An toàn nhất} (trong nhóm Dynamic Scaling), chứng minh tính khả thi để áp dụng vào môi trường thực tế.